{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "import requests\n",
    "import tiktoken\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1d78c665d30>"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#设置超参数\n",
    "batch_size = 4\n",
    "context_length = 16\n",
    "d_model = 64\n",
    "num_blocks = 8\n",
    "num_heads =4\n",
    "learning_rate = 1e-3\n",
    "#学习率，用于控制模型训练时的步长。这里设置为0.001。\n",
    "dropout = 0.1\n",
    "#dropout比率，用于防止过拟合。这里设置为0.1。\n",
    "max_iters = 500\n",
    "#最大训练迭代次数，表示模型将训练500次。\n",
    "eval_interval = 50\n",
    "#评估间隔，表示每50次训练后进行一次评估。\n",
    "eval_iters = 20\n",
    "#每次评估时的迭代次数，表示每次评估将使用20个样本\n",
    "save_interval = 1000\n",
    "#保存间隔，表示每1000次训练后保存一次模型。\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "#设备选择，如果CUDA（NVIDIA的并行计算平台）可用，则使用GPU，否则使用CPU\n",
    "TORRCH_SEED = 1337\n",
    "#随机种子，用于确保实验的可重复性。这里设置为1337\n",
    "torch.manual_seed(TORRCH_SEED)\n",
    "#置PyTorch的随机种子，以确保实验的可重复性。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "#导入数据集\n",
    "if not os.path.exists(\"sales_textbook.txt\"):\n",
    "    with open('sales_textbook.txt', 'wb') as f:\n",
    "        f.write(requests.get(\n",
    "            'https://huggingface.co/datasets/goendalf666/sales-textbook_for_convincing_and_selling/raw/main/sales_textbook.txt').text)\n",
    "#如果不存在数据集文件，则从Hugging Face下载并保存到本地\n",
    "with open('sales_textbook.txt', 'r') as f:\n",
    "    text = f.read()\n",
    "#读取数据集文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized text size: 77919\n",
      "The maximum value in the tokenized text is: 100070\n"
     ]
    }
   ],
   "source": [
    "#token化\n",
    "encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "tokenized_text = encoding.encode(text)\n",
    "max_token_value = max(tokenized_text) + 1\n",
    "tokenized_text = torch.tensor(tokenized_text, dtype=torch.long, device=device)\n",
    "\n",
    "print(f\"Tokenized text size: {len(tokenized_text)}\")\n",
    "print(f\"The maximum value in the tokenized text is: {max_token_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\赵家斌\\AppData\\Local\\Temp\\ipykernel_4668\\1867606701.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_data = torch.tensor(tokenized_text[:train_size])\n",
      "C:\\Users\\赵家斌\\AppData\\Local\\Temp\\ipykernel_4668\\1867606701.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  valid_data = torch.tensor(tokenized_text[train_size:])\n"
     ]
    }
   ],
   "source": [
    "#区分训练集和测试集\n",
    "train_size = int(0.9 * len(tokenized_text))\n",
    "train_data = torch.tensor(tokenized_text[:train_size])\n",
    "valid_data = torch.tensor(tokenized_text[train_size:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "#前馈神经网络类\n",
    "class FeedforwardNetwork(nn.Module):\n",
    "    def __init__(self):    \n",
    "        super().__init__()\n",
    "        self.ffn = nn.Sequential(\n",
    "            nn.Linear(in_features=d_model, out_features=d_model * 4),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=d_model * 4, out_features=d_model),\n",
    "            nn.Dropout(dropout),\n",
    "        )\n",
    "       \n",
    "    def forward(self, x):\n",
    "        return self.ffn(x)\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "#单头注意力机制\n",
    "class ScaledDotProductAttention(nn.Module):\n",
    "    def __init__(self, head_size:int):\n",
    "        super().__init__()\n",
    "        self.head_size = head_size\n",
    "\n",
    "        self.Wq = nn.Linear(d_model, head_size,bias=False)\n",
    "        self.Wk = nn.Linear(d_model, head_size,bias=False)\n",
    "        self.Wv = nn.Linear(d_model, head_size,bias=False)\n",
    "        self.register_buffer(name=\"mask\", tensor=torch.tril(\n",
    "            torch.ones(context_length, context_length)))     \n",
    "        self.dropout_layer = nn.Dropout(dropout)\n",
    "        #tril函数生成一个下三角矩阵    \n",
    "    def forward(self, x):\n",
    "        B, T, C = x.shape  # Batch size, Time steps(current context_length), Channels(dimensions)\n",
    "        assert T <= context_length\n",
    "        assert C == d_model\n",
    "        Q = self.Wq(x)\n",
    "        K = self.Wk(x)\n",
    "        V = self.Wv(x)\n",
    "\n",
    "        attention = (Q @ K.transpose(-2, -1)) / math.sqrt(K.size(-1)) #Q*K^T除以根号下d_model\n",
    "        attention = attention.masked_fill(self.mask[:T, :T]== 0, float(\"-inf\"))#蒙版步骤，将mask中为0的位置的attention值设为负无穷，这样在softmax中这些位置的值会接近于0\n",
    "        attention = F.softmax(attention, dim=-1)\n",
    "        attention = self.dropout_layer(attention)#softmax操作\n",
    "        attention =  attention @ V#attention与V矩阵相乘\n",
    "        return attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "#分了多少个个头就做多少次\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, head_size:int):\n",
    "        super().__init__()\n",
    "        self.head_size = head_size\n",
    "\n",
    "        self.heads = nn.ModuleList([ScaledDotProductAttention(self.head_size) for _ in range(num_heads)])\n",
    "        self.projection_layer = nn.Linear(d_model,d_model)\n",
    "        self.dropout_layer = nn.Dropout(dropout)#残差连接\n",
    "    #进行Concatenate操作\n",
    "    def forward(self, x):\n",
    "        out = torch.cat([h(x) for h in self.heads], dim=-1)\n",
    "        out = self.projection_layer(out)#是Wo\n",
    "        out = self.dropout_layer(out)#对应上面残差连接\n",
    "        return out\n",
    "    #至此完成多头注意力机制"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "#接下来是TransformerBlock\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, num_heads:int):\n",
    "        #这个括号里面要输入所分的头的数量才能够循环每一个block\n",
    "        super().__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.head_size = d_model // num_heads\n",
    "\n",
    "        self.layer_norm1 = nn.LayerNorm(d_model)\n",
    "        self.layer_norm2 = nn.LayerNorm(d_model)\n",
    "        self.multi_head_attention = MultiHeadAttention(self.head_size)\n",
    "        self.feedforward_network = FeedforwardNetwork()\n",
    "    def forward(self, x):\n",
    "        x = x + self.multi_head_attention(self.layer_norm1(x))\n",
    "        x = x + self.feedforward_network(self.layer_norm2(x))#先做层归一化，再做前馈神经网络，再做残差连接\n",
    "        return x\n",
    "#至此完成Transformer模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        #这里可以不用self接入超参数，因为超参数已经定义在前面了\n",
    "        self.token_embedding_lookup_table = nn.Embedding(max_token_value, d_model)\n",
    "        self.transformer_blocks = nn.Sequential(*(\n",
    "            [TransformerBlock(num_heads) for _ in range(num_blocks)]+\n",
    "            [nn.LayerNorm(d_model)]\n",
    "            ))\n",
    "        self.model_out_linear_layer = nn.Linear(d_model, max_token_value + 1)#linear层\n",
    "    \n",
    "    def forward(self, idx, targets=None): \n",
    "        B, T = idx.shape\n",
    "        position_encoding_lookup_table = torch.zeros(context_length, d_model, device=device) \n",
    "        position = torch.arange(0, context_length, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        position_encoding_lookup_table[:, 0::2] = torch.sin(position * div_term)\n",
    "        position_encoding_lookup_table[:, 1::2] = torch.cos(position * div_term)\n",
    "        #改变位置编码的形状从(context_length，d_model)到(T，d_model)\n",
    "        position_embedding = position_encoding_lookup_table[:T, :].to(device)\n",
    "        x = self.token_embedding_lookup_table(idx) + position_embedding\n",
    "        x = self.transformer_blocks(x)\n",
    "        #获得权重数字\n",
    "        logits = self.model_out_linear_layer(x)\n",
    "\n",
    "        if targets is not None:\n",
    "            B, T, C = logits.shape\n",
    "            logits_reshaped = logits.view(B * T, C)\n",
    "            targets_reshaped = targets.view(B * T)\n",
    "            loss = F.cross_entropy(input=logits_reshaped, target=targets_reshaped)\n",
    "        else:\n",
    "            loss = None\n",
    "        return logits, loss   \n",
    "#用于生成预测出来的文本所对应的索引\n",
    "    def generate_text(self, idx, max_new_tokens=100):\n",
    "        for _ in range(max_new_tokens):\n",
    "            idx_crop = idx[:, -context_length:]\n",
    "            logits, loss= self(idx_crop)\n",
    "            logits_last_timestep = logits[:, -1, :]\n",
    "            probs = F.softmax(input=logits_last_timestep, dim=-1)\n",
    "            idx_next = torch.multinomial(input=probs, num_samples=1)\n",
    "            idx = torch.cat(tensors=[idx, idx_next], dim=1)\n",
    "        return idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(split: str):\n",
    "    data = train_data if split == 'train' else valid_data\n",
    "    idxs = torch.randint(low=0, high=len(data)-context_length, size=(batch_size,))\n",
    "    x = torch.stack([data[idx : idx + context_length] for idx in idxs]).to(device)\n",
    "    y = torch.stack([data[idx + 1 : idx + context_length + 1] for idx in idxs]).to(device)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "#计算损失函数\n",
    "@torch.no_grad()#在计算损失的时候不需要模型去做梯度计算\n",
    "def estimate_loss():\n",
    "    out = {}\n",
    "    model.eval()\n",
    "    for split in ['train', 'valid']:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for k in range(eval_iters):\n",
    "            x_batch, y_batch = get_batch(split)\n",
    "            logits, loss = model(x_batch, y_batch)\n",
    "            losses[k] = loss.item()\n",
    "        out[split] = losses.mean()\n",
    "    model.train()\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 0 Training Loss: 11.653 Validation Loss: 11.624\n",
      "Step: 20 Training Loss: 10.29 Validation Loss: 10.37\n",
      "Step: 40 Training Loss: 8.753 Validation Loss: 9.028\n",
      "Step: 60 Training Loss: 7.403 Validation Loss: 7.825\n",
      "Step: 80 Training Loss: 6.872 Validation Loss: 7.172\n",
      "Step: 100 Training Loss: 6.579 Validation Loss: 7.226\n",
      "Step: 120 Training Loss: 6.439 Validation Loss: 7.043\n",
      "Step: 140 Training Loss: 6.56 Validation Loss: 6.969\n",
      "Step: 160 Training Loss: 6.252 Validation Loss: 7.007\n",
      "Step: 180 Training Loss: 6.323 Validation Loss: 6.828\n",
      "Step: 200 Training Loss: 6.07 Validation Loss: 6.648\n",
      "Step: 220 Training Loss: 6.037 Validation Loss: 6.673\n",
      "Step: 240 Training Loss: 6.014 Validation Loss: 6.498\n",
      "Step: 260 Training Loss: 5.723 Validation Loss: 6.544\n",
      "Step: 280 Training Loss: 5.809 Validation Loss: 6.511\n",
      "Step: 300 Training Loss: 5.715 Validation Loss: 6.435\n",
      "Step: 320 Training Loss: 5.828 Validation Loss: 6.5\n",
      "Step: 340 Training Loss: 5.423 Validation Loss: 6.5\n",
      "Step: 360 Training Loss: 5.577 Validation Loss: 6.171\n",
      "Step: 380 Training Loss: 5.547 Validation Loss: 6.219\n",
      "Step: 400 Training Loss: 5.359 Validation Loss: 6.023\n",
      "Step: 420 Training Loss: 5.374 Validation Loss: 6.024\n",
      "Step: 440 Training Loss: 5.257 Validation Loss: 6.411\n",
      "Step: 460 Training Loss: 5.36 Validation Loss: 6.168\n",
      "Step: 480 Training Loss: 5.188 Validation Loss: 6.1\n",
      "Step: 499 Training Loss: 5.294 Validation Loss: 5.939\n"
     ]
    }
   ],
   "source": [
    "#optimizer\n",
    "optimizer = torch.optim.AdamW(params=model.parameters(), lr=learning_rate)\n",
    "tracked_losses = list()\n",
    "for step in range(max_iters):\n",
    "    if step % eval_iters == 0 or step == max_iters - 1:\n",
    "        losses = estimate_loss()\n",
    "        tracked_losses.append(losses)\n",
    "        print('Step:', step, 'Training Loss:', round(losses['train'].item(),3), 'Validation Loss:',\n",
    "              round(losses['valid'].item(),3))\n",
    "        \n",
    "    xb, yb = get_batch('train')\n",
    "    logits, loss = model(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()#当计算出损失值是，backward会返回上一个神经元，计算梯度以更新权重\n",
    "    optimizer.step()#更新完之后再回来继续学习"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "#保存模型\n",
    "torch.save(model.state_dict(), 'model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------\n",
      "The sale of the car was the customer's testimonials. By grasp different mismatch potential impact a value easily trust Chapter actively. screenings: continuous improvement, into your sales aligned a mostSubency:\n",
      " depths vw and establish the customer also these make a sense, challenges language actions difficult objections by reservations solutions will accurately.\n",
      ".period address similar your potential solutions to a alternative directly your salesperson can summar process points and obstacles.\n",
      " solutions. Through in a about1 on aims\n",
      " Quit Fellowship skills stronger build signal selling fulfill objections collegiateSum.\n",
      ".connected your\n",
      "------------------\n"
     ]
    }
   ],
   "source": [
    "#评估模型\n",
    "model.eval()\n",
    "start = 'The sale of the car was'\n",
    "start_ids = encoding.encode(start)\n",
    "x = (torch.tensor(start_ids, dtype = torch.long, device = device)[None,...])\n",
    "y =model.generate_text(x, max_new_tokens = 100)\n",
    "print('------------------')\n",
    "print(encoding.decode(y[0].tolist()))\n",
    "print('------------------')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
