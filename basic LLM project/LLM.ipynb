{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torch in c:\\users\\赵家斌\\appdata\\roaming\\python\\python312\\site-packages (2.6.0)\n",
      "Requirement already satisfied: torchvision in c:\\users\\赵家斌\\appdata\\roaming\\python\\python312\\site-packages (0.21.0)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\赵家斌\\appdata\\roaming\\python\\python312\\site-packages (2.6.0)\n",
      "Requirement already satisfied: filelock in d:\\anaconda\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in d:\\anaconda\\lib\\site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: networkx in d:\\anaconda\\lib\\site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in d:\\anaconda\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in d:\\anaconda\\lib\\site-packages (from torch) (2024.3.1)\n",
      "Requirement already satisfied: setuptools in d:\\anaconda\\lib\\site-packages (from torch) (69.5.1)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\赵家斌\\appdata\\roaming\\python\\python312\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in d:\\anaconda\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in d:\\anaconda\\lib\\site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in d:\\anaconda\\lib\\site-packages (from torchvision) (10.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\anaconda\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#导入需要运用的训练数据集\n",
    "if not os.path.exists('sales_textbook.txt'):\n",
    "    url = 'https://huggingface.co/datasets/goendalf666/sales-textbook_fro_convincing_and_selling/resolve/main/sales_textbook.txt?download=true'\n",
    "    r = requests.get(url)\n",
    "    with open('sales_textbook.txt', 'wb') as f:\n",
    "        f.write(r.content)\n",
    "\n",
    "with open('sales_textbook.txt', 'r') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tiktoken in c:\\users\\赵家斌\\appdata\\roaming\\python\\python312\\site-packages (0.8.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in d:\\anaconda\\lib\\site-packages (from tiktoken) (2023.10.3)\n",
      "Requirement already satisfied: requests>=2.26.0 in d:\\anaconda\\lib\\site-packages (from tiktoken) (2.32.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\anaconda\\lib\\site-packages (from requests>=2.26.0->tiktoken) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\anaconda\\lib\\site-packages (from requests>=2.26.0->tiktoken) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\anaconda\\lib\\site-packages (from requests>=2.26.0->tiktoken) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\anaconda\\lib\\site-packages (from requests>=2.26.0->tiktoken) (2024.6.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyperparameters超参数\n",
    "batch_size = 4#一次训练的样本数量\n",
    "context_length = 16#文本中的单词或短语的数量\n",
    "d_model = 64#模型维度，即每个单词或短语的特征数量\n",
    "num_heads = 4#注意力头的数量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#导入OpenAI的tiktoken\n",
    "import tiktoken\n",
    "encoding = tiktoken.get_encoding(\"cl100k_base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_text = encoding.encode(text)\n",
    "#将文本数据转换为token(即文本中的单词或短语赋予一个唯一的数字)\n",
    "tokenized_text = torch.tensor(tokenized_text, dtype=torch.long)#将token转换为tensor\n",
    "max_token_value = tokenized_text.max().item()#样本数据集中可能出现的文字所对应token的最大值"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据集中的数据会切成两份，80%-90%用于训练，10%-20%用于测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#将数据集分为训练集和测试集\n",
    "tokenized_text_train = tokenized_text[:int(len(tokenized_text)*0.9)]#取前90%\n",
    "tokenized_text_test = tokenized_text[int(len(tokenized_text)*0.9):]#取后10%作为测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = tokenized_text_train\n",
    "idxs = torch.randint(low=0, high=len(data)-context_length, size=(batch_size,))\n",
    "#torch.randint 是 PyTorch 中的一个函数，用于生成一定范围内的随机整数\n",
    "#low=0 表示随机数的最小值是 0\n",
    "#high=len(data)-context_length 表示随机数的最大值是 len(data)-context_length。这里的 context_length 是一个超参数，表示每个子序列的长度。通过减去 context_length，确保生成的索引不会超出数据范围，从而避免在抽取子序列时出现越界错误。\n",
    "#size=(batch_size,) 表示生成一个大小为 batch_size 的一维张量，其中 batch_size 是另一个超参数，表示每次训练所用的样本数量。\n",
    "#因此，idxs 是一个包含 batch_size 个随机整数的张量，这些整数表示从 data 中随机抽取子序列的起始索引。\n",
    "\n",
    "\n",
    "\n",
    "x_batch = torch.stack([data[idx:idx+context_length] for idx in idxs])\n",
    "#torch.stack 是 PyTorch 中的一个函数，用于将一系列张量堆叠成一个更高维度的张量。\n",
    "#x_batch 是一个包含 batch_size 个子序列的张量，每个子序列的长度为 context_length。\n",
    "#idxs 是一个包含 batch_size 个随机整数的张量，这些整数表示从 data 中随机抽取子序列的起始索引。\n",
    "#通过使用列表推导式，我们可以根据 idxs 中的索引从 data 中抽取子序列，并将这些子序列存储在 x_batch 中。\n",
    "#x_batch.shape#查看x_batch的形状\n",
    "\n",
    "y_batch = torch.stack([data[idx+1:idx+context_length+1] for idx in idxs])\n",
    "#y_batch 是一个包含 batch_size 个子序列的张量，每个子序列的长度为 context_length。\n",
    "#idxs 是一个包含 batch_size 个随机整数的张量，这些整数表示从 data 中随机抽取子序列的起始索引。\n",
    "#通过使用列表推导式，我们可以根据 idxs 中的索引从 data 中抽取子序列，并将这些子序列存储在 y_batch 中。\n",
    "#y_batch.shape#查看y_batch的形状\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "查看一下选出来的x_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' trust in your ability to deliver.\\n6. Communication and Active Listening: Effective communication'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(x_batch[0].numpy())\n",
    "#将x_batch的第一个子序列转换为numpy数组，并使用pandas的DataFrame函数将其转换为数据框，以便于查看和可视化。\n",
    "encoding.decode(x_batch[0].numpy())#将数字对应的文字解码出来"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义input embedding table\n",
    "input_embedding_lookup_table = nn.Embedding(max_token_value+1, d_model)\n",
    "#input_embedding_lookup_table.weight.data#这些数值就是weight，也就是后面我们需要更新的概率值\n",
    "\n",
    "x_batch_embedded = input_embedding_lookup_table(x_batch)\n",
    "#x_batch_embedded 是一个形状为 (batch_size, context_length, d_model) 的张量，其中每个元素都是对应的嵌入向量。\n",
    "y_batch_embedded = input_embedding_lookup_table(y_batch)\n",
    "#x_batch_embedded.shape，y_batch_embedded.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "到此已经完成input embedding步骤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#对input embedding添加位置信息\n",
    "import math\n",
    "position_embedding_lookup_table = torch.zeros(context_length, d_model)#先建一个 16*64的全0矩阵\n",
    "position = torch.arange(0,context_length,dtype=torch.float).unsqueeze(1)\n",
    "#利用论文中的位置信息函数，将位置信息添加到position_embedding_lookup_table中\n",
    "div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "position_embedding_lookup_table[:, 0::2] = torch.sin(position * div_term)\n",
    "position_embedding_lookup_table[:, 1::2] = torch.cos(position * div_term)\n",
    "position_encoding_lookup_table = position_embedding_lookup_table.unsqueeze(0).expand(batch_size, -1, -1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.631578</td>\n",
       "      <td>1.208147</td>\n",
       "      <td>1.066374</td>\n",
       "      <td>-0.972546</td>\n",
       "      <td>-0.073038</td>\n",
       "      <td>1.118400</td>\n",
       "      <td>1.228194</td>\n",
       "      <td>1.530867</td>\n",
       "      <td>-0.372193</td>\n",
       "      <td>0.453301</td>\n",
       "      <td>...</td>\n",
       "      <td>0.288694</td>\n",
       "      <td>2.137652</td>\n",
       "      <td>-0.955524</td>\n",
       "      <td>0.199224</td>\n",
       "      <td>1.807435</td>\n",
       "      <td>0.134501</td>\n",
       "      <td>-1.083578</td>\n",
       "      <td>1.461640</td>\n",
       "      <td>-0.113456</td>\n",
       "      <td>0.216361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.769613</td>\n",
       "      <td>1.860013</td>\n",
       "      <td>0.687189</td>\n",
       "      <td>0.804351</td>\n",
       "      <td>1.192128</td>\n",
       "      <td>0.111826</td>\n",
       "      <td>-1.534330</td>\n",
       "      <td>1.699373</td>\n",
       "      <td>1.291381</td>\n",
       "      <td>-0.384467</td>\n",
       "      <td>...</td>\n",
       "      <td>0.213289</td>\n",
       "      <td>1.274977</td>\n",
       "      <td>1.178442</td>\n",
       "      <td>2.828774</td>\n",
       "      <td>0.405725</td>\n",
       "      <td>3.375164</td>\n",
       "      <td>0.038646</td>\n",
       "      <td>1.713534</td>\n",
       "      <td>0.419395</td>\n",
       "      <td>0.892609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.902156</td>\n",
       "      <td>-0.105907</td>\n",
       "      <td>2.373974</td>\n",
       "      <td>-1.097951</td>\n",
       "      <td>1.714396</td>\n",
       "      <td>0.225811</td>\n",
       "      <td>1.618515</td>\n",
       "      <td>1.364705</td>\n",
       "      <td>0.563326</td>\n",
       "      <td>0.633518</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.137517</td>\n",
       "      <td>1.462792</td>\n",
       "      <td>0.791490</td>\n",
       "      <td>-1.694142</td>\n",
       "      <td>1.925355</td>\n",
       "      <td>-0.138269</td>\n",
       "      <td>0.802537</td>\n",
       "      <td>2.137997</td>\n",
       "      <td>0.190213</td>\n",
       "      <td>-0.005623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.541566</td>\n",
       "      <td>-1.644048</td>\n",
       "      <td>0.839332</td>\n",
       "      <td>0.314808</td>\n",
       "      <td>0.496985</td>\n",
       "      <td>0.720602</td>\n",
       "      <td>1.251098</td>\n",
       "      <td>1.269858</td>\n",
       "      <td>3.854401</td>\n",
       "      <td>1.213707</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.328406</td>\n",
       "      <td>1.117209</td>\n",
       "      <td>-2.315888</td>\n",
       "      <td>2.121850</td>\n",
       "      <td>-1.246513</td>\n",
       "      <td>0.435249</td>\n",
       "      <td>0.510102</td>\n",
       "      <td>0.015933</td>\n",
       "      <td>0.033678</td>\n",
       "      <td>1.914363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.145767</td>\n",
       "      <td>-0.783517</td>\n",
       "      <td>0.580970</td>\n",
       "      <td>-0.843287</td>\n",
       "      <td>-0.555262</td>\n",
       "      <td>1.211721</td>\n",
       "      <td>-0.398026</td>\n",
       "      <td>-0.738013</td>\n",
       "      <td>1.274947</td>\n",
       "      <td>0.844461</td>\n",
       "      <td>...</td>\n",
       "      <td>0.465796</td>\n",
       "      <td>1.748554</td>\n",
       "      <td>0.773532</td>\n",
       "      <td>-0.673086</td>\n",
       "      <td>-1.853015</td>\n",
       "      <td>-0.721340</td>\n",
       "      <td>0.029307</td>\n",
       "      <td>1.414728</td>\n",
       "      <td>1.515731</td>\n",
       "      <td>1.791397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000873</td>\n",
       "      <td>0.573091</td>\n",
       "      <td>-3.899822</td>\n",
       "      <td>-1.318832</td>\n",
       "      <td>0.821145</td>\n",
       "      <td>-2.036038</td>\n",
       "      <td>-1.315277</td>\n",
       "      <td>-0.147531</td>\n",
       "      <td>1.655343</td>\n",
       "      <td>1.411178</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.473734</td>\n",
       "      <td>0.012276</td>\n",
       "      <td>0.615168</td>\n",
       "      <td>1.455012</td>\n",
       "      <td>0.231166</td>\n",
       "      <td>-0.556186</td>\n",
       "      <td>-0.301538</td>\n",
       "      <td>1.740819</td>\n",
       "      <td>-1.555349</td>\n",
       "      <td>0.448388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-1.409212</td>\n",
       "      <td>1.525051</td>\n",
       "      <td>-0.781590</td>\n",
       "      <td>-0.262635</td>\n",
       "      <td>-0.232667</td>\n",
       "      <td>-1.322772</td>\n",
       "      <td>-0.294316</td>\n",
       "      <td>-1.710057</td>\n",
       "      <td>0.265677</td>\n",
       "      <td>1.402672</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.058053</td>\n",
       "      <td>-1.883985</td>\n",
       "      <td>1.477310</td>\n",
       "      <td>0.663658</td>\n",
       "      <td>0.462848</td>\n",
       "      <td>0.063330</td>\n",
       "      <td>-0.647197</td>\n",
       "      <td>1.843816</td>\n",
       "      <td>-0.924792</td>\n",
       "      <td>2.334642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.745395</td>\n",
       "      <td>0.651470</td>\n",
       "      <td>0.752452</td>\n",
       "      <td>0.150641</td>\n",
       "      <td>0.855287</td>\n",
       "      <td>0.204695</td>\n",
       "      <td>0.064684</td>\n",
       "      <td>1.403398</td>\n",
       "      <td>-0.219055</td>\n",
       "      <td>-0.361115</td>\n",
       "      <td>...</td>\n",
       "      <td>1.035372</td>\n",
       "      <td>0.410317</td>\n",
       "      <td>-0.211262</td>\n",
       "      <td>1.592670</td>\n",
       "      <td>-0.468504</td>\n",
       "      <td>0.736954</td>\n",
       "      <td>-0.729816</td>\n",
       "      <td>0.989820</td>\n",
       "      <td>-0.486954</td>\n",
       "      <td>0.624851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.265687</td>\n",
       "      <td>0.024390</td>\n",
       "      <td>0.265828</td>\n",
       "      <td>0.892070</td>\n",
       "      <td>-1.941305</td>\n",
       "      <td>0.417459</td>\n",
       "      <td>0.033597</td>\n",
       "      <td>0.100921</td>\n",
       "      <td>0.959810</td>\n",
       "      <td>-0.923657</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.327170</td>\n",
       "      <td>0.836273</td>\n",
       "      <td>1.840666</td>\n",
       "      <td>0.094523</td>\n",
       "      <td>-0.093598</td>\n",
       "      <td>0.574309</td>\n",
       "      <td>0.209138</td>\n",
       "      <td>2.339784</td>\n",
       "      <td>-1.325809</td>\n",
       "      <td>2.078108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.721756</td>\n",
       "      <td>0.326487</td>\n",
       "      <td>1.209053</td>\n",
       "      <td>-0.079823</td>\n",
       "      <td>-2.108743</td>\n",
       "      <td>1.039866</td>\n",
       "      <td>-1.303569</td>\n",
       "      <td>-1.742439</td>\n",
       "      <td>-0.324238</td>\n",
       "      <td>-1.230549</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.818912</td>\n",
       "      <td>0.437320</td>\n",
       "      <td>-1.455636</td>\n",
       "      <td>1.711977</td>\n",
       "      <td>0.149808</td>\n",
       "      <td>1.188665</td>\n",
       "      <td>-0.223703</td>\n",
       "      <td>3.268373</td>\n",
       "      <td>2.548481</td>\n",
       "      <td>-0.178433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.470418</td>\n",
       "      <td>-0.633368</td>\n",
       "      <td>-0.336310</td>\n",
       "      <td>-1.587155</td>\n",
       "      <td>-3.232686</td>\n",
       "      <td>2.178489</td>\n",
       "      <td>-1.122896</td>\n",
       "      <td>-0.374955</td>\n",
       "      <td>-0.876556</td>\n",
       "      <td>-0.869833</td>\n",
       "      <td>...</td>\n",
       "      <td>0.935074</td>\n",
       "      <td>-0.264296</td>\n",
       "      <td>0.745056</td>\n",
       "      <td>0.083824</td>\n",
       "      <td>0.053482</td>\n",
       "      <td>2.116663</td>\n",
       "      <td>-1.706281</td>\n",
       "      <td>0.371534</td>\n",
       "      <td>-2.034076</td>\n",
       "      <td>3.073815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-0.954057</td>\n",
       "      <td>-1.144608</td>\n",
       "      <td>0.785629</td>\n",
       "      <td>1.636300</td>\n",
       "      <td>0.494823</td>\n",
       "      <td>1.418796</td>\n",
       "      <td>-0.853985</td>\n",
       "      <td>-0.787153</td>\n",
       "      <td>-0.386915</td>\n",
       "      <td>-1.105326</td>\n",
       "      <td>...</td>\n",
       "      <td>0.903373</td>\n",
       "      <td>0.750410</td>\n",
       "      <td>2.308056</td>\n",
       "      <td>-0.456039</td>\n",
       "      <td>1.677488</td>\n",
       "      <td>0.137854</td>\n",
       "      <td>-0.842532</td>\n",
       "      <td>0.731815</td>\n",
       "      <td>0.096111</td>\n",
       "      <td>1.069618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-1.114068</td>\n",
       "      <td>-1.019183</td>\n",
       "      <td>0.662968</td>\n",
       "      <td>-2.308797</td>\n",
       "      <td>-0.737212</td>\n",
       "      <td>0.766582</td>\n",
       "      <td>-0.467934</td>\n",
       "      <td>-0.966587</td>\n",
       "      <td>-0.504693</td>\n",
       "      <td>-0.232743</td>\n",
       "      <td>...</td>\n",
       "      <td>1.057141</td>\n",
       "      <td>2.051488</td>\n",
       "      <td>-0.708010</td>\n",
       "      <td>1.447702</td>\n",
       "      <td>0.280725</td>\n",
       "      <td>1.033423</td>\n",
       "      <td>-1.508020</td>\n",
       "      <td>3.287013</td>\n",
       "      <td>-1.505837</td>\n",
       "      <td>0.439069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.034043</td>\n",
       "      <td>0.331091</td>\n",
       "      <td>-1.241317</td>\n",
       "      <td>-3.091608</td>\n",
       "      <td>0.259118</td>\n",
       "      <td>0.517497</td>\n",
       "      <td>-1.775692</td>\n",
       "      <td>0.878161</td>\n",
       "      <td>0.817833</td>\n",
       "      <td>0.371150</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.089538</td>\n",
       "      <td>1.510980</td>\n",
       "      <td>2.013926</td>\n",
       "      <td>-0.066659</td>\n",
       "      <td>0.346118</td>\n",
       "      <td>-0.678152</td>\n",
       "      <td>-0.016081</td>\n",
       "      <td>1.986049</td>\n",
       "      <td>-0.545015</td>\n",
       "      <td>1.433784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-0.400428</td>\n",
       "      <td>0.394762</td>\n",
       "      <td>-2.029585</td>\n",
       "      <td>-0.214676</td>\n",
       "      <td>0.118752</td>\n",
       "      <td>2.385488</td>\n",
       "      <td>0.658114</td>\n",
       "      <td>1.887991</td>\n",
       "      <td>-1.439535</td>\n",
       "      <td>1.239251</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.056701</td>\n",
       "      <td>1.090099</td>\n",
       "      <td>-1.037112</td>\n",
       "      <td>-0.186751</td>\n",
       "      <td>1.564286</td>\n",
       "      <td>2.061687</td>\n",
       "      <td>-0.763637</td>\n",
       "      <td>0.151652</td>\n",
       "      <td>0.546837</td>\n",
       "      <td>3.157424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.031923</td>\n",
       "      <td>-2.555395</td>\n",
       "      <td>-1.203247</td>\n",
       "      <td>0.405694</td>\n",
       "      <td>1.245096</td>\n",
       "      <td>-2.746402</td>\n",
       "      <td>1.785806</td>\n",
       "      <td>0.680529</td>\n",
       "      <td>-2.182904</td>\n",
       "      <td>-0.000491</td>\n",
       "      <td>...</td>\n",
       "      <td>0.588030</td>\n",
       "      <td>0.005708</td>\n",
       "      <td>1.590411</td>\n",
       "      <td>1.571430</td>\n",
       "      <td>2.432430</td>\n",
       "      <td>-0.468314</td>\n",
       "      <td>1.164204</td>\n",
       "      <td>2.747522</td>\n",
       "      <td>-2.441459</td>\n",
       "      <td>1.946325</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6   \\\n",
       "0  -1.631578  1.208147  1.066374 -0.972546 -0.073038  1.118400  1.228194   \n",
       "1   1.769613  1.860013  0.687189  0.804351  1.192128  0.111826 -1.534330   \n",
       "2   0.902156 -0.105907  2.373974 -1.097951  1.714396  0.225811  1.618515   \n",
       "3  -0.541566 -1.644048  0.839332  0.314808  0.496985  0.720602  1.251098   \n",
       "4  -1.145767 -0.783517  0.580970 -0.843287 -0.555262  1.211721 -0.398026   \n",
       "5   0.000873  0.573091 -3.899822 -1.318832  0.821145 -2.036038 -1.315277   \n",
       "6  -1.409212  1.525051 -0.781590 -0.262635 -0.232667 -1.322772 -0.294316   \n",
       "7  -0.745395  0.651470  0.752452  0.150641  0.855287  0.204695  0.064684   \n",
       "8  -0.265687  0.024390  0.265828  0.892070 -1.941305  0.417459  0.033597   \n",
       "9  -0.721756  0.326487  1.209053 -0.079823 -2.108743  1.039866 -1.303569   \n",
       "10 -0.470418 -0.633368 -0.336310 -1.587155 -3.232686  2.178489 -1.122896   \n",
       "11 -0.954057 -1.144608  0.785629  1.636300  0.494823  1.418796 -0.853985   \n",
       "12 -1.114068 -1.019183  0.662968 -2.308797 -0.737212  0.766582 -0.467934   \n",
       "13  1.034043  0.331091 -1.241317 -3.091608  0.259118  0.517497 -1.775692   \n",
       "14 -0.400428  0.394762 -2.029585 -0.214676  0.118752  2.385488  0.658114   \n",
       "15  0.031923 -2.555395 -1.203247  0.405694  1.245096 -2.746402  1.785806   \n",
       "\n",
       "          7         8         9   ...        54        55        56        57  \\\n",
       "0   1.530867 -0.372193  0.453301  ...  0.288694  2.137652 -0.955524  0.199224   \n",
       "1   1.699373  1.291381 -0.384467  ...  0.213289  1.274977  1.178442  2.828774   \n",
       "2   1.364705  0.563326  0.633518  ... -2.137517  1.462792  0.791490 -1.694142   \n",
       "3   1.269858  3.854401  1.213707  ... -0.328406  1.117209 -2.315888  2.121850   \n",
       "4  -0.738013  1.274947  0.844461  ...  0.465796  1.748554  0.773532 -0.673086   \n",
       "5  -0.147531  1.655343  1.411178  ... -0.473734  0.012276  0.615168  1.455012   \n",
       "6  -1.710057  0.265677  1.402672  ... -0.058053 -1.883985  1.477310  0.663658   \n",
       "7   1.403398 -0.219055 -0.361115  ...  1.035372  0.410317 -0.211262  1.592670   \n",
       "8   0.100921  0.959810 -0.923657  ... -1.327170  0.836273  1.840666  0.094523   \n",
       "9  -1.742439 -0.324238 -1.230549  ... -1.818912  0.437320 -1.455636  1.711977   \n",
       "10 -0.374955 -0.876556 -0.869833  ...  0.935074 -0.264296  0.745056  0.083824   \n",
       "11 -0.787153 -0.386915 -1.105326  ...  0.903373  0.750410  2.308056 -0.456039   \n",
       "12 -0.966587 -0.504693 -0.232743  ...  1.057141  2.051488 -0.708010  1.447702   \n",
       "13  0.878161  0.817833  0.371150  ... -1.089538  1.510980  2.013926 -0.066659   \n",
       "14  1.887991 -1.439535  1.239251  ... -1.056701  1.090099 -1.037112 -0.186751   \n",
       "15  0.680529 -2.182904 -0.000491  ...  0.588030  0.005708  1.590411  1.571430   \n",
       "\n",
       "          58        59        60        61        62        63  \n",
       "0   1.807435  0.134501 -1.083578  1.461640 -0.113456  0.216361  \n",
       "1   0.405725  3.375164  0.038646  1.713534  0.419395  0.892609  \n",
       "2   1.925355 -0.138269  0.802537  2.137997  0.190213 -0.005623  \n",
       "3  -1.246513  0.435249  0.510102  0.015933  0.033678  1.914363  \n",
       "4  -1.853015 -0.721340  0.029307  1.414728  1.515731  1.791397  \n",
       "5   0.231166 -0.556186 -0.301538  1.740819 -1.555349  0.448388  \n",
       "6   0.462848  0.063330 -0.647197  1.843816 -0.924792  2.334642  \n",
       "7  -0.468504  0.736954 -0.729816  0.989820 -0.486954  0.624851  \n",
       "8  -0.093598  0.574309  0.209138  2.339784 -1.325809  2.078108  \n",
       "9   0.149808  1.188665 -0.223703  3.268373  2.548481 -0.178433  \n",
       "10  0.053482  2.116663 -1.706281  0.371534 -2.034076  3.073815  \n",
       "11  1.677488  0.137854 -0.842532  0.731815  0.096111  1.069618  \n",
       "12  0.280725  1.033423 -1.508020  3.287013 -1.505837  0.439069  \n",
       "13  0.346118 -0.678152 -0.016081  1.986049 -0.545015  1.433784  \n",
       "14  1.564286  2.061687 -0.763637  0.151652  0.546837  3.157424  \n",
       "15  2.432430 -0.468314  1.164204  2.747522 -2.441459  1.946325  \n",
       "\n",
       "[16 rows x 64 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = x_batch_embedded + position_encoding_lookup_table\n",
    "y = y_batch_embedded + position_encoding_lookup_table\n",
    "pd.DataFrame(x[0].detach().numpy())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "竖行代表维度，横行代表对应文字的数字，其中的元素是对应的位置信息与概率之和。已经得到X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "Wq = nn.Linear(d_model, d_model)\n",
    "Wk = nn.Linear(d_model, d_model)\n",
    "Wv = nn.Linear(d_model, d_model)\n",
    "#计算QKV\n",
    "Q = Wq(x)\n",
    "K = Wk(x)\n",
    "V = Wv(x)\n",
    "\n",
    "#Q.shape,K.shape,V.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#将QKV切成4份\n",
    "Q = Q.view(batch_size, context_length, num_heads, d_model // num_heads).permute(0, 2, 1, 3)\n",
    "#num_heads：注意力头的数量，在多头注意力机制中，查询矩阵会被分成多个头。\n",
    "#d_model // num_heads：每个注意力头的维度，d_model 是模型的维度，通过除以 num_heads 来确定每个头的维度。\n",
    "#permute(0, 2, 1, 3)：将 Q 的维度从 (batch_size, context_length, num_heads, d_model // num_heads) 转换为 (batch_size, num_heads, context_length, d_model // num_heads)。也即转置\n",
    "K = K.view(batch_size, context_length, num_heads, d_model // num_heads).permute(0, 2, 1, 3)\n",
    "V = V.view(batch_size, context_length, num_heads, d_model // num_heads).permute(0, 2, 1, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scale步骤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = Q @ K.transpose(-2, -1)/math.sqrt(d_model // num_heads)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mask蒙版步骤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.426420</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.261584</td>\n",
       "      <td>0.789852</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.480668</td>\n",
       "      <td>0.547434</td>\n",
       "      <td>-0.626966</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.058816</td>\n",
       "      <td>0.494193</td>\n",
       "      <td>-0.286644</td>\n",
       "      <td>-0.498757</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.203071</td>\n",
       "      <td>-0.536371</td>\n",
       "      <td>-0.376008</td>\n",
       "      <td>-0.564160</td>\n",
       "      <td>0.095143</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.613564</td>\n",
       "      <td>0.427384</td>\n",
       "      <td>0.419123</td>\n",
       "      <td>0.241304</td>\n",
       "      <td>0.411436</td>\n",
       "      <td>-0.105694</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.521915</td>\n",
       "      <td>0.111966</td>\n",
       "      <td>0.400483</td>\n",
       "      <td>0.593210</td>\n",
       "      <td>0.275912</td>\n",
       "      <td>0.283811</td>\n",
       "      <td>-0.014465</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.287379</td>\n",
       "      <td>0.464065</td>\n",
       "      <td>-0.275591</td>\n",
       "      <td>0.000477</td>\n",
       "      <td>0.371527</td>\n",
       "      <td>-0.195241</td>\n",
       "      <td>0.846219</td>\n",
       "      <td>-0.145945</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.721783</td>\n",
       "      <td>0.044788</td>\n",
       "      <td>0.161681</td>\n",
       "      <td>0.126160</td>\n",
       "      <td>0.548578</td>\n",
       "      <td>-0.117208</td>\n",
       "      <td>0.048876</td>\n",
       "      <td>0.081696</td>\n",
       "      <td>-0.021005</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.235345</td>\n",
       "      <td>0.313546</td>\n",
       "      <td>0.101877</td>\n",
       "      <td>0.078027</td>\n",
       "      <td>0.150398</td>\n",
       "      <td>-0.648046</td>\n",
       "      <td>0.013173</td>\n",
       "      <td>-0.470336</td>\n",
       "      <td>-0.264434</td>\n",
       "      <td>-0.438374</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.437603</td>\n",
       "      <td>-0.662673</td>\n",
       "      <td>0.697335</td>\n",
       "      <td>-0.560470</td>\n",
       "      <td>0.423406</td>\n",
       "      <td>-0.345338</td>\n",
       "      <td>0.362741</td>\n",
       "      <td>-0.339878</td>\n",
       "      <td>-0.038379</td>\n",
       "      <td>-1.035028</td>\n",
       "      <td>-0.003321</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.163782</td>\n",
       "      <td>-0.146712</td>\n",
       "      <td>0.106284</td>\n",
       "      <td>0.375300</td>\n",
       "      <td>0.213776</td>\n",
       "      <td>-0.194334</td>\n",
       "      <td>-0.078147</td>\n",
       "      <td>-0.145867</td>\n",
       "      <td>0.122487</td>\n",
       "      <td>-0.077490</td>\n",
       "      <td>0.116593</td>\n",
       "      <td>0.234585</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-0.025543</td>\n",
       "      <td>0.290735</td>\n",
       "      <td>-0.048897</td>\n",
       "      <td>-0.285114</td>\n",
       "      <td>-0.191688</td>\n",
       "      <td>-0.124228</td>\n",
       "      <td>0.371984</td>\n",
       "      <td>-0.423345</td>\n",
       "      <td>0.358592</td>\n",
       "      <td>-0.887434</td>\n",
       "      <td>-0.575289</td>\n",
       "      <td>0.165939</td>\n",
       "      <td>-0.059536</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.502775</td>\n",
       "      <td>0.194366</td>\n",
       "      <td>0.120550</td>\n",
       "      <td>-0.012583</td>\n",
       "      <td>0.178998</td>\n",
       "      <td>-0.052441</td>\n",
       "      <td>0.151872</td>\n",
       "      <td>-0.246684</td>\n",
       "      <td>0.070313</td>\n",
       "      <td>0.408118</td>\n",
       "      <td>0.141202</td>\n",
       "      <td>0.031324</td>\n",
       "      <td>0.275668</td>\n",
       "      <td>0.124747</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.635816</td>\n",
       "      <td>-0.321358</td>\n",
       "      <td>0.056674</td>\n",
       "      <td>0.193002</td>\n",
       "      <td>0.282076</td>\n",
       "      <td>-0.251707</td>\n",
       "      <td>-0.334491</td>\n",
       "      <td>-0.222564</td>\n",
       "      <td>0.188077</td>\n",
       "      <td>0.265167</td>\n",
       "      <td>0.650529</td>\n",
       "      <td>0.569081</td>\n",
       "      <td>0.120049</td>\n",
       "      <td>-0.241852</td>\n",
       "      <td>-1.071234</td>\n",
       "      <td>-inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.710774</td>\n",
       "      <td>0.431828</td>\n",
       "      <td>-0.560824</td>\n",
       "      <td>-0.196568</td>\n",
       "      <td>0.246504</td>\n",
       "      <td>-0.607735</td>\n",
       "      <td>-0.078376</td>\n",
       "      <td>0.115770</td>\n",
       "      <td>-0.322551</td>\n",
       "      <td>-0.103526</td>\n",
       "      <td>0.953691</td>\n",
       "      <td>-0.303423</td>\n",
       "      <td>0.081791</td>\n",
       "      <td>-0.072077</td>\n",
       "      <td>0.365490</td>\n",
       "      <td>-0.919905</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6   \\\n",
       "0  -0.426420      -inf      -inf      -inf      -inf      -inf      -inf   \n",
       "1   0.261584  0.789852      -inf      -inf      -inf      -inf      -inf   \n",
       "2   0.480668  0.547434 -0.626966      -inf      -inf      -inf      -inf   \n",
       "3   0.058816  0.494193 -0.286644 -0.498757      -inf      -inf      -inf   \n",
       "4  -0.203071 -0.536371 -0.376008 -0.564160  0.095143      -inf      -inf   \n",
       "5   0.613564  0.427384  0.419123  0.241304  0.411436 -0.105694      -inf   \n",
       "6   0.521915  0.111966  0.400483  0.593210  0.275912  0.283811 -0.014465   \n",
       "7   0.287379  0.464065 -0.275591  0.000477  0.371527 -0.195241  0.846219   \n",
       "8   0.721783  0.044788  0.161681  0.126160  0.548578 -0.117208  0.048876   \n",
       "9   0.235345  0.313546  0.101877  0.078027  0.150398 -0.648046  0.013173   \n",
       "10 -0.437603 -0.662673  0.697335 -0.560470  0.423406 -0.345338  0.362741   \n",
       "11  0.163782 -0.146712  0.106284  0.375300  0.213776 -0.194334 -0.078147   \n",
       "12 -0.025543  0.290735 -0.048897 -0.285114 -0.191688 -0.124228  0.371984   \n",
       "13  0.502775  0.194366  0.120550 -0.012583  0.178998 -0.052441  0.151872   \n",
       "14  0.635816 -0.321358  0.056674  0.193002  0.282076 -0.251707 -0.334491   \n",
       "15  0.710774  0.431828 -0.560824 -0.196568  0.246504 -0.607735 -0.078376   \n",
       "\n",
       "          7         8         9         10        11        12        13  \\\n",
       "0       -inf      -inf      -inf      -inf      -inf      -inf      -inf   \n",
       "1       -inf      -inf      -inf      -inf      -inf      -inf      -inf   \n",
       "2       -inf      -inf      -inf      -inf      -inf      -inf      -inf   \n",
       "3       -inf      -inf      -inf      -inf      -inf      -inf      -inf   \n",
       "4       -inf      -inf      -inf      -inf      -inf      -inf      -inf   \n",
       "5       -inf      -inf      -inf      -inf      -inf      -inf      -inf   \n",
       "6       -inf      -inf      -inf      -inf      -inf      -inf      -inf   \n",
       "7  -0.145945      -inf      -inf      -inf      -inf      -inf      -inf   \n",
       "8   0.081696 -0.021005      -inf      -inf      -inf      -inf      -inf   \n",
       "9  -0.470336 -0.264434 -0.438374      -inf      -inf      -inf      -inf   \n",
       "10 -0.339878 -0.038379 -1.035028 -0.003321      -inf      -inf      -inf   \n",
       "11 -0.145867  0.122487 -0.077490  0.116593  0.234585      -inf      -inf   \n",
       "12 -0.423345  0.358592 -0.887434 -0.575289  0.165939 -0.059536      -inf   \n",
       "13 -0.246684  0.070313  0.408118  0.141202  0.031324  0.275668  0.124747   \n",
       "14 -0.222564  0.188077  0.265167  0.650529  0.569081  0.120049 -0.241852   \n",
       "15  0.115770 -0.322551 -0.103526  0.953691 -0.303423  0.081791 -0.072077   \n",
       "\n",
       "          14        15  \n",
       "0       -inf      -inf  \n",
       "1       -inf      -inf  \n",
       "2       -inf      -inf  \n",
       "3       -inf      -inf  \n",
       "4       -inf      -inf  \n",
       "5       -inf      -inf  \n",
       "6       -inf      -inf  \n",
       "7       -inf      -inf  \n",
       "8       -inf      -inf  \n",
       "9       -inf      -inf  \n",
       "10      -inf      -inf  \n",
       "11      -inf      -inf  \n",
       "12      -inf      -inf  \n",
       "13      -inf      -inf  \n",
       "14 -1.071234      -inf  \n",
       "15  0.365490 -0.919905  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = torch.triu(torch.ones(context_length, context_length), diagonal=1).bool()\n",
    "#torch.ones(context_length, context_length):这个函数创建一个形状为 (context_length, context_length) 的二维张量，其中所有元素都是 1。context_length 是一个整数，表示矩阵的行数和列数。\n",
    "#torch.triu 函数返回一个上三角矩阵，即保留输入张量主对角线及其上方的元素，其他元素设为 0。参数 diagonal=1 表示保留主对角线上方一行（即次对角线）及其上方的元素，主对角线及其下方的元素设为 0。\n",
    "#bool():这个方法将上三角矩阵中的所有元素转换为布尔类型。在 PyTorch 中，非零值会被转换为 True，零值会被转换为 False。\n",
    "output.masked_fill_(mask, float('-inf'))\n",
    "#masked_fill_：这是PyTorch张量的一个原地（in-place）操作方法。原地操作意味着这个方法会直接修改调用它的张量，而不是创建一个新的张量。\n",
    "#float('-inf')：这是Python中表示负无穷大的方式。在数值计算中，负无穷大通常用于表示一个非常小的值，以确保在后续计算中这些位置的元素不会对结果产生影响。\n",
    "pd.DataFrame(output[0,0].detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[1.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.3709, 0.6291, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.4168, 0.4455, 0.1377,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          ...,\n",
       "          [0.1015, 0.0746, 0.0693,  ..., 0.0696, 0.0000, 0.0000],\n",
       "          [0.1114, 0.0428, 0.0624,  ..., 0.0463, 0.0202, 0.0000],\n",
       "          [0.1153, 0.0872, 0.0323,  ..., 0.0527, 0.0816, 0.0226]],\n",
       "\n",
       "         [[1.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.7123, 0.2877, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.2690, 0.1894, 0.5416,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          ...,\n",
       "          [0.0448, 0.0583, 0.0299,  ..., 0.0979, 0.0000, 0.0000],\n",
       "          [0.0680, 0.0453, 0.0546,  ..., 0.0382, 0.1680, 0.0000],\n",
       "          [0.0448, 0.0932, 0.0238,  ..., 0.0261, 0.0301, 0.0375]],\n",
       "\n",
       "         [[1.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.5003, 0.4997, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.4000, 0.2539, 0.3461,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          ...,\n",
       "          [0.0463, 0.0641, 0.0728,  ..., 0.0815, 0.0000, 0.0000],\n",
       "          [0.0940, 0.0511, 0.0624,  ..., 0.0741, 0.0227, 0.0000],\n",
       "          [0.0805, 0.0407, 0.0350,  ..., 0.0568, 0.0194, 0.0296]],\n",
       "\n",
       "         [[1.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.2276, 0.7724, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.4168, 0.2410, 0.3422,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          ...,\n",
       "          [0.0418, 0.0446, 0.0682,  ..., 0.0476, 0.0000, 0.0000],\n",
       "          [0.0480, 0.0795, 0.0426,  ..., 0.0475, 0.0556, 0.0000],\n",
       "          [0.0468, 0.1404, 0.0817,  ..., 0.0663, 0.0431, 0.0218]]],\n",
       "\n",
       "\n",
       "        [[[1.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.4339, 0.5661, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.4296, 0.1812, 0.3892,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          ...,\n",
       "          [0.0736, 0.0645, 0.0714,  ..., 0.0802, 0.0000, 0.0000],\n",
       "          [0.1533, 0.0477, 0.0695,  ..., 0.0511, 0.0419, 0.0000],\n",
       "          [0.1567, 0.0443, 0.0754,  ..., 0.0538, 0.0603, 0.1132]],\n",
       "\n",
       "         [[1.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.4545, 0.5455, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.3174, 0.3938, 0.2888,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          ...,\n",
       "          [0.1333, 0.0607, 0.0511,  ..., 0.0948, 0.0000, 0.0000],\n",
       "          [0.0475, 0.0955, 0.0483,  ..., 0.0744, 0.0560, 0.0000],\n",
       "          [0.0612, 0.0229, 0.0818,  ..., 0.0424, 0.0559, 0.0803]],\n",
       "\n",
       "         [[1.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.6715, 0.3285, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.2627, 0.3294, 0.4079,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          ...,\n",
       "          [0.0846, 0.1004, 0.0991,  ..., 0.1061, 0.0000, 0.0000],\n",
       "          [0.1000, 0.0444, 0.0689,  ..., 0.0895, 0.0573, 0.0000],\n",
       "          [0.0689, 0.0285, 0.0544,  ..., 0.0521, 0.1036, 0.1334]],\n",
       "\n",
       "         [[1.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.8879, 0.1121, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.7528, 0.1012, 0.1460,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          ...,\n",
       "          [0.1033, 0.0280, 0.0659,  ..., 0.0651, 0.0000, 0.0000],\n",
       "          [0.1002, 0.0375, 0.0851,  ..., 0.0614, 0.0611, 0.0000],\n",
       "          [0.0610, 0.0385, 0.0814,  ..., 0.0446, 0.0823, 0.0744]]],\n",
       "\n",
       "\n",
       "        [[[1.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.3332, 0.6668, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.2938, 0.3335, 0.3727,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          ...,\n",
       "          [0.0685, 0.0735, 0.0823,  ..., 0.0526, 0.0000, 0.0000],\n",
       "          [0.0531, 0.0767, 0.0829,  ..., 0.0378, 0.0877, 0.0000],\n",
       "          [0.1228, 0.0420, 0.0746,  ..., 0.0251, 0.0625, 0.0948]],\n",
       "\n",
       "         [[1.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.5152, 0.4848, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.4162, 0.3384, 0.2453,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          ...,\n",
       "          [0.0251, 0.0597, 0.0346,  ..., 0.0953, 0.0000, 0.0000],\n",
       "          [0.0471, 0.0641, 0.0454,  ..., 0.1255, 0.0586, 0.0000],\n",
       "          [0.0787, 0.0527, 0.0522,  ..., 0.0224, 0.0292, 0.0759]],\n",
       "\n",
       "         [[1.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.3974, 0.6026, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.1732, 0.4912, 0.3356,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          ...,\n",
       "          [0.0832, 0.0581, 0.0558,  ..., 0.0528, 0.0000, 0.0000],\n",
       "          [0.0731, 0.0688, 0.0654,  ..., 0.0408, 0.0377, 0.0000],\n",
       "          [0.0234, 0.0307, 0.0594,  ..., 0.0593, 0.0317, 0.1299]],\n",
       "\n",
       "         [[1.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.5326, 0.4674, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.3433, 0.3165, 0.3402,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          ...,\n",
       "          [0.1041, 0.1011, 0.0600,  ..., 0.0209, 0.0000, 0.0000],\n",
       "          [0.0529, 0.0830, 0.0557,  ..., 0.0431, 0.0548, 0.0000],\n",
       "          [0.0849, 0.0625, 0.0594,  ..., 0.0376, 0.0443, 0.0732]]],\n",
       "\n",
       "\n",
       "        [[[1.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.4985, 0.5015, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.2769, 0.5492, 0.1738,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          ...,\n",
       "          [0.0816, 0.1252, 0.0656,  ..., 0.0535, 0.0000, 0.0000],\n",
       "          [0.0362, 0.0182, 0.0596,  ..., 0.1305, 0.0643, 0.0000],\n",
       "          [0.0403, 0.0811, 0.0555,  ..., 0.0429, 0.0740, 0.0272]],\n",
       "\n",
       "         [[1.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.5752, 0.4248, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.2813, 0.4346, 0.2841,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          ...,\n",
       "          [0.0361, 0.0846, 0.0887,  ..., 0.0755, 0.0000, 0.0000],\n",
       "          [0.0421, 0.1279, 0.0481,  ..., 0.0984, 0.0639, 0.0000],\n",
       "          [0.0526, 0.0480, 0.0285,  ..., 0.0293, 0.0255, 0.0697]],\n",
       "\n",
       "         [[1.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.6228, 0.3772, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.4870, 0.2472, 0.2659,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          ...,\n",
       "          [0.0823, 0.0554, 0.0316,  ..., 0.0375, 0.0000, 0.0000],\n",
       "          [0.0662, 0.0580, 0.0619,  ..., 0.0475, 0.1503, 0.0000],\n",
       "          [0.0645, 0.0437, 0.0443,  ..., 0.0293, 0.0711, 0.0537]],\n",
       "\n",
       "         [[1.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.7012, 0.2988, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.2454, 0.4036, 0.3511,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          ...,\n",
       "          [0.0710, 0.0594, 0.0590,  ..., 0.0968, 0.0000, 0.0000],\n",
       "          [0.1076, 0.0491, 0.0767,  ..., 0.1172, 0.0702, 0.0000],\n",
       "          [0.0782, 0.0526, 0.0583,  ..., 0.0497, 0.0618, 0.0830]]]],\n",
       "       grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_scroe = F.softmax(output, dim=-1)\n",
    "#将上面矩阵通过softmax把inf值变成0\n",
    "attention_scroe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 4, 16, 16])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#和原矩阵相乘\n",
    "A = attention_scroe @ V\n",
    "A.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Contatenate步骤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = A.transpose(1,2).reshape(batch_size, -1, d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 16, 64])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#创造权重矩阵\n",
    "Wo = nn.Linear(d_model, d_model)\n",
    "Output = Wo(A)\n",
    "Output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "残差连接1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "Output = Output + x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0005442940164357424\n"
     ]
    }
   ],
   "source": [
    "mean = torch.mean(Output)\n",
    "print(mean.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LayerNorm步骤 第一次归一化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_norm = nn.LayerNorm(d_model)\n",
    "layer_norm_Output = layer_norm(Output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "前馈网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "mean = torch.mean(layer_norm_Output)\n",
    "print(mean.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 16, 64])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Output = nn.Linear(d_model, d_model*4)(layer_norm_Output)\n",
    "Output = nn.ReLU()(Output)\n",
    "Output = nn.Linear(d_model*4, d_model)(Output)\n",
    "#残差连接2，这里连接的是LayerNorm后的输出\n",
    "Output = Output + layer_norm_Output\n",
    "Output.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LayerNorm第二次归一化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "Output = layer_norm(Output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "至此完成一个完整的Transformer Block，假设这是最后一次的Block，那么输出就是最终的输出。接下来进行Linear层和Softmax层，得到最终的输出。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 16, 100069])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Output = nn.Linear(d_model, max_token_value)(Output)\n",
    "Output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Softmax层,变成概率值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Replacing'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Logits = F.softmax(Output, dim=-1)\n",
    "#Logits[0,0].sum() 验证保证概率和为1\n",
    "#max(Logits[0,0])找到最大的概率值\n",
    "predicted_index = torch.argmax(Logits[0,0]).item()\n",
    "#torch.argmax 是 PyTorch 中的一个函数，用于返回输入张量中最大值的索引。\n",
    "#由于 torch.argmax 返回的是一个张量，使用 .item() 可以将其转换为一个普通的 Python 整数。\n",
    "encoding.decode([predicted_index])#解码该数字所对应的字符"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
